{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"About Me","text":""},{"location":"#turn-friction-into-flow","title":"Turn friction into flow","text":""},{"location":"#30-years-turning-complex-technical-challenges-into-business-results","title":"30+ years turning complex technical challenges into business results","text":"<ul> <li> <p>Is your team losing hours to repetitive tasks that should be automated?</p> </li> <li> <p>Are operational bottlenecks preventing your business from scaling?</p> </li> <li> <p>Do you need someone who can both architect and build the solution?</p> </li> <li> <p>Looking for proven expertise across multiple industries and technologies?</p> </li> <li> <p>Want a consultant who delivers working systems, not just slide decks?</p> </li> </ul> <p>Book a Free Call </p>"},{"location":"#about-me","title":"About me","text":"<p>I'm Jan, an AI automation consultant based in the Netherlands, working with European businesses that are ready to transform operational bottlenecks into competitive advantages. If your organization is losing valuable time to manual processes, struggling to scale operations, or watching competitors pull ahead with smarter systems\u2014I can help you change that.</p> <p>My background is anything but typical for this field. I hold a PhD in Nuclear Reactor Physics from TU Delft, which gave me a rigorous foundation in complex systems thinking and analytical problem-solving. Over the past three decades, I've built mission-critical systems across healthcare, aerospace, defense, and finance\u2014sectors where downtime costs lives, money, or missions. From 24/7 alarm systems to banking platforms with financial penalties for outages, I've learned to build systems that simply cannot fail.</p> <p>I've helped scale companies like DirectorInsight and Zintouch from small teams to 40-50 employees, engineering infrastructure to support 100% YoY user growth. In 2025, I earned my certification as a Datalumina AI Engineer, combining my deep development expertise with cutting-edge AI capabilities.</p> <p>My tech stack spans Python, modern AI frameworks, API development, database architecture, and enterprise integration. But more importantly, I understand how technology serves business goals\u2014not the other way around.</p> <p>I work through Imperial Automation, my consultancy focused on AI-powered process automation for European businesses. For business inquiries, project scoping, or formal proposals, visit imperial-automation.eu.</p>"},{"location":"#why-work-with-me","title":"Why work with me?","text":"<p>Here's what sets me apart and how I can help transform your operations:</p> <ul> <li> <p> Builder, Not Just Advisor</p> <p>I don't hand you a report and walk away. I architect solutions, build them hands-on, or lead your dev team to delivery. You get a technical co-founder mindset applied to your automation challenges\u2014someone who writes the code, not just the recommendations.</p> </li> <li> <p> Proven Scale Experience</p> <p>I've built the systems that enabled companies to grow from small teams to 40-50 employees. I understand what breaks at scale and how to build automation that grows with your business, not against it.</p> </li> <li> <p> Enterprise-Grade Background</p> <p>Three decades across healthcare, aerospace, defense, and finance means I understand compliance, security, and reliability requirements. Your automation will be built to standards that matter.</p> </li> <li> <p> Scientific Rigor</p> <p>A PhD trains you to solve problems others consider impossible. I bring that same analytical depth to understanding your bottlenecks and designing solutions that address root causes, not symptoms.</p> </li> <li> <p> Mission-Critical Mindset</p> <p>Three decades building systems where failure isn't an option\u2014from life-safety alarm systems to financial trading platforms with downtime penalties, from spacecraft systems to national infrastructure. I design for zero-downtime upgrades and build reliability into every layer.</p> </li> </ul>"},{"location":"#industries-expertise","title":"Industries &amp; expertise","text":"<ul> <li> <p> Healthcare</p> <p>Built mission-critical alarm systems at Zintouch requiring 24/7 availability where downtime could cost lives. Supported year-over-year user base doubling through management dashboards, third-party integrations, and expanded alarm system support\u2014all while maintaining zero-downtime upgrades. Deep experience with GDPR, medical data standards, and high-stakes reliability.</p> </li> <li> <p> Finance</p> <p>Developed solutions at DirectorInsight for financial reporting and analysis, scaling 24/7 infrastructure to support global users and year-over-year user growth doubling. Experience with regulatory requirements, audit trails, and the precision financial systems demand.</p> </li> <li> <p> Aerospace &amp; Defense</p> <p>Worked with ESA, TNO, and Atos on spacecraft and defense systems where failure isn't an option\u2014once in space, there are no repairs. This background shapes how I approach reliability and testing in every project.</p> </li> <li> <p> Banking &amp; Trading</p> <p>Built trading systems at ABN AMRO with financial penalties for downtime. When missed orders cost real money and market opportunities vanish in seconds, you learn to build systems that never fail.</p> </li> <li> <p> Enterprise Integration</p> <p>Specialized in connecting disparate systems, automating data flows, and building bridges between legacy infrastructure and modern AI capabilities.</p> </li> </ul>"},{"location":"#frequently-asked-questions","title":"Frequently asked questions","text":"What kind of automation projects do you take on? <p>I focus on high-ROI automation opportunities\u2014processes that consume significant manual effort, create bottlenecks, or prevent scaling. This includes document processing, data pipeline automation, workflow optimization, and AI-enhanced business processes. I'm selective about projects to ensure I can deliver meaningful results.</p> Do you work remotely with European clients? <p>Yes, I'm fully set up for remote collaboration across Europe. I use modern communication tools, provide regular progress updates, and can accommodate different time zones. For larger engagements, I'm available for on-site workshops when needed.</p> What's your approach to a new project? <p>I start with a focused discovery phase to understand your bottleneck, quantify the impact, and identify the right solution approach. I provide a clear proposal with expected ROI before any development begins. No surprises, no scope creep.</p> How do you handle data security? <p>With my background in defense and healthcare, security isn't an afterthought\u2014it's foundational. I sign comprehensive NDAs, follow enterprise security practices, and can work within your existing security infrastructure. GDPR compliance is standard.</p> What's your pricing model? <p>I work on a project basis with clear deliverables and timelines. Pricing reflects the value delivered and complexity involved, not hours logged. For ongoing automation support, I offer retainer arrangements. Let's discuss your specific situation to find the right structure.</p> How quickly can you start? <p>Typically within 1-2 weeks of agreement. For urgent situations, I can often accommodate faster starts. The discovery phase usually takes 1-2 weeks, followed by a detailed proposal before development begins.</p> What if we're not sure automation is the right solution? <p>That's exactly what the initial strategy call is for. I'll help you evaluate whether automation makes sense for your situation, estimate potential ROI, and identify the best approach. No obligation, no pressure\u2014just honest assessment.</p> <ul> <li> <p> Let's discuss your bottleneck</p> <p>Every automation journey starts with understanding the problem. Schedule a free 30-minute strategy call to explore your challenges and see if we're a good fit.</p> <p>Book a Free Call </p> </li> </ul>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2026/02/27/claudemd-doesnt-work-say-researchers-but-is-that-true/","title":"CLAUDE.md Doesn't Work (Say Researchers). But Is That True?","text":"<p>Why academic research on context files tells a different story than daily practice with AI coding agents.</p> <p></p> <p>Last week I came across a paper from researchers at ETH Z\u00fcrich that made me pause: \"Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?\" Their conclusion is surprising at first glance: context files like CLAUDE.md and AGENTS.md do not make coding agents better. In fact, auto-generated context files make them 3% worse on average, while increasing costs by over 20%.</p> <p>As someone who works with Claude Code daily and invests significant time refining CLAUDE.md files, my first reaction was: that doesn't match my experience at all. But that reaction itself gave me pause. It's easy to blindly adopt advice from tool-makers telling you to use instruction files like CLAUDE.md. Especially when your own experience seems to confirm that advice. In a field moving as fast as ours, it's tempting to keep running and never stop to ask: does this actually work, or do I just believe it works?</p> <p>This paper made me reflect. And that alone makes it valuable.</p>"},{"location":"blog/2026/02/27/claudemd-doesnt-work-say-researchers-but-is-that-true/#what-the-researchers-found","title":"What the Researchers Found","text":"<p>The ETH Z\u00fcrich team built a new benchmark called AGENTbench, with 138 tasks from 12 GitHub repositories. They tested coding agents in three scenarios: without a context file, with an LLM-generated context file following developer recommendations, and with a human-written context file. The results were sobering.</p> <p>LLM-generated context files (think the <code>/init</code> command in Claude Code) produced a slight decrease in task resolution on average. Human-written context files yielded only a marginal improvement of about 4%. In both cases, costs rose significantly because the agent explored more, tested more, and reasoned more. The instructions were followed. But paradoxically, that often made tasks harder rather than easier.</p> <p>The researchers conclude that context files are in many cases \"redundant documentation.\" The information they contain can often be derived by the agent from the codebase itself. And when they include unnecessary requirements, the problem only gets worse.</p>"},{"location":"blog/2026/02/27/claudemd-doesnt-work-say-researchers-but-is-that-true/#why-my-experience-differs","title":"Why My Experience Differs","text":"<p>Yet I don't recognise the conclusion that CLAUDE.md is pointless. I think the difference can be explained by three factors.</p> <p>The benchmark measures something different from my daily work. The researchers use isolated GitHub issues as tasks: fix a bug, add a feature, validated by unit tests. That's a well-defined, bounded problem. In practice, I use Claude Code for something entirely different: building production software where architectural decisions, code style, project conventions, and consistency across files are crucial. My CLAUDE.md doesn't contain generic information about the codebase. It contains decisions. Which patterns we use. How error handling looks. Which libraries we do and don't use. An agent cannot derive that kind of context from code alone.</p> <p>My CLAUDE.md is iteratively refined, not auto-generated. One of the strongest findings from the research is that LLM-generated context files actually lower performance. That doesn't surprise me. An <code>/init</code> command produces a generic summary of your codebase. That is fundamentally different from a carefully curated document that, after weeks of trial and error, contains exactly the instructions that make the difference. The researchers found that even stronger models don't generate better context files. That confirms my experience: the value isn't in describing what exists. It's in prescribing what should happen.</p> <p>Models are getting better, and so is their interaction with context files. The research was conducted with a specific snapshot of models. But anyone working with Claude Code daily notices that both the models and the tooling improve rapidly. Instructions that were ignored six months ago are now followed precisely. The interplay between human and model evolves continuously. So does the effectiveness of a well-maintained CLAUDE.md file. The research offers a snapshot. Practice is an ongoing process.</p>"},{"location":"blog/2026/02/27/claudemd-doesnt-work-say-researchers-but-is-that-true/#where-the-research-is-right","title":"Where the Research Is Right","text":"<p>At the same time, the paper contains valuable insights I take to heart.</p> <p>The finding that context files lead to more exploration and higher costs rings true. If you include too many instructions, especially vague or contradictory ones, the agent spends more time without producing better results. The researchers' recommendation to keep context files minimal and include only essential requirements is solid advice. Less is more. Every line in your CLAUDE.md must earn its place.</p> <p>The warning against auto-generated context files is also justified. <code>/init</code> is a fine starting point. But if you don't drastically edit and sharpen the result, it does you little good. Or worse: it works against you.</p>"},{"location":"blog/2026/02/27/claudemd-doesnt-work-say-researchers-but-is-that-true/#my-advice","title":"My Advice","text":"<p>If you work with Claude Code, here is my advice based on both the research and my own experience:</p> <p>Don't use <code>/init</code> as a finished product. Feel free to generate a starting point. But treat it as a rough draft that needs fundamental rewriting.</p> <p>Keep your CLAUDE.md short and prescriptive. Don't describe what the codebase is. The agent can figure that out itself. Describe what the agent should do: which patterns to follow, which tools to use, which mistakes to avoid.</p> <p>Delegate tasks to scripts, not to the LLM. One of the most valuable insights from the research is that specific tooling instructions contribute the most. Think about which commands to run and which scripts are available. This aligns with a shift I'm going through myself: delegating more and more tasks explicitly to scripts and tools instead of to the LLM. Linting, formatting, running tests, database migrations. The LLM doesn't need to figure these out on its own. By clearly describing in your CLAUDE.md which tasks are handled by which scripts, you prevent the agent from improvising where a deterministic script is more reliable. Newer variants like SKILL.md files make this even more explicit by describing per capability what the agent does itself and what it delegates to external tools.</p> <p>Iterate continuously. A CLAUDE.md is a living document. When the agent makes a mistake, you add an instruction. But equally important: clean up regularly. I do this both manually and with the help of the LLM itself. Models are excellent at spotting duplicate instructions, sharpening vague formulations, and summarising outdated rules. After a few weeks of intensive work, a CLAUDE.md naturally outgrows itself. Instructions that were once relevant become outdated because the model now handles things correctly by default, or because your codebase has changed. Without regular cleanup, your context file accumulates exactly the ballast the researchers warn about: unnecessary requirements that make the agent explore more without producing better results.</p> <p>Be critical about cost. More instructions means more tokens, more exploration, more cost. Measure whether your instructions actually produce better results, or just more activity.</p>"},{"location":"blog/2026/02/27/claudemd-doesnt-work-say-researchers-but-is-that-true/#conclusion","title":"Conclusion","text":"<p>Let me start by saying: I deeply appreciate this research. It's exactly the kind of scientific scrutiny our field needs. Too often, best practices for AI tooling are based on anecdotes, blog posts, and vendor recommendations. Including my own. That researchers at ETH Z\u00fcrich take the effort to build a rigorous benchmark and actually measure the effectiveness of context files is of great value.</p> <p>I also realise how difficult this type of research is. Models evolve rapidly. The tooling around them changes continuously. The way practitioners use their context files shifts accordingly. By the time you've built a benchmark, collected data, and published your paper, the landscape has already changed. That's not a criticism of the researchers. It's a fundamental challenge of doing research in a field that moves at this speed.</p> <p>What I'd welcome is for this kind of research to be repeated more often. And where possible, brought closer to daily practice. Not just isolated issue resolution, but also long-running projects where architectural decisions, code style, and project conventions play a role. Not just auto-generated context files, but also iteratively refined files from experienced users. That's easier said than done. But the foundation this team has laid with AGENTbench is an excellent starting point.</p> <p>The conclusion remains nuanced. Context files are not a magic solution. Auto-generated files can do more harm than good. But a well-maintained CLAUDE.md is not just documentation. It's a translation of your architectural decisions, coding standards, and project knowledge into a format your AI partner understands. That takes investment, iteration, and discipline. But when you get it right, you notice the difference.</p> <p>What I take away most of all: the willingness to question my own assumptions. I'll continue using CLAUDE.md. But with sharper eyes. And with gratitude towards researchers who push us to not just build, but also pause and reflect from time to time.</p> <p>Reference: Gloaguen, T., M\u00fcndler, N., M\u00fcller, M., Raychev, V., &amp; Vechev, M. (2025). Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents? arXiv:2602.11988</p>"},{"location":"blog/2026/02/23/why-your-compliance-team-is-drowning-in-paper---and-how-ai-changes-the-equation/","title":"Why Your Compliance Team Is Drowning in Paper - And How AI Changes the Equation","text":"<p>Somewhere in your organisation right now, someone is reading a 200-page contract. Not because they enjoy it. Because a clause on page 147 might conflict with a regulation that changed six weeks ago. And if they miss it, it becomes a problem that lands on someone else's desk three months from now - except by then, no one remembers why the decision was made.</p> <p>That's compliance work for most mid-sized companies. Not dramatic courtroom moments. Just people with highlighters, spreadsheets, and a growing stack of documents that all need to be checked against rules that keep changing. The Association of Corporate Counsel puts the manual error rate at 15 to 25 percent. Not because people are careless, but because the volume is inhuman. You can't read 400 contracts a quarter and catch every detail.</p> <p>Now imagine a system that reads those same documents in minutes. Not to make the decision - that still requires a person who understands the context. But to extract the relevant clauses, flag what changed since last quarter, and highlight where the risk sits. The compliance officer still reviews it. They just don't spend four hours getting to the point where they can start thinking.</p> <p>JPMorgan built exactly this. Their COiN system processes 12,000 commercial loan agreements and extracts 150 contract attributes - in seconds. Work that previously took lawyers and loan officers 360,000 hours per year. That's not a typo. And compliance errors dropped by roughly 80 percent, because the system doesn't get tired on page 193.</p> <p>Deutsche Telekom's legal team uses AI to condense lengthy regulations into actionable summaries, structure litigation documents, and navigate complex tender processes. Their lawyers reclaim an estimated five hours per week. Not by doing less work, but by spending less time on the mechanical part of it.</p> <p>This is catching on. A White &amp; Case survey of 265 compliance and legal professionals found that 88 percent of those using AI apply it to document summarisation. McKinsey reports 30 to 40 percent time savings on document analysis tasks in compliance functions. These aren't projections. These are measurements from teams already doing it.</p> <p>The pattern is consistent: AI handles the reading, extracting, and cross-referencing. Humans handle the judgment. The result isn't fewer compliance people. It's compliance people who actually have time to think about risk instead of drowning in paper.</p>"},{"location":"blog/2026/02/23/why-your-compliance-team-is-drowning-in-paper---and-how-ai-changes-the-equation/#sources","title":"Sources","text":"<p>Manual error rates in contract review The Association of Corporate Counsel (ACC) reports that manual contract review produces inconsistent results with error rates between 15-25%, particularly during high-volume periods or when conducted by junior staff. This figure is widely referenced in legal technology benchmarking studies.</p> <p>JPMorgan Chase - COiN (Contract Intelligence) JPMorgan's AI system processes 12,000 commercial loan agreements and extracts 150 contract attributes in seconds - work that previously required 360,000 hours of manual review per year by lawyers and loan officers. Compliance-related errors were reduced by approximately 80%.</p> <ul> <li>ABA Journal - JPMorgan Chase uses tech to save 360,000 hours of annual work</li> <li>Futurism - An AI completed 360,000 hours of finance work in just seconds</li> </ul> <p>Deutsche Telekom - Harvey AI Deutsche Telekom's in-house legal team uses Harvey AI to condense regulations into actionable insights, structure litigation documents, and accelerate tender processes. Lawyers reclaim an estimated 5 hours per week.</p> <ul> <li>Harvey AI - How Harvey saves lawyers time</li> </ul> <p>White &amp; Case - 2025 Global Compliance Risk Benchmarking Survey In a survey of 265 senior compliance, legal, and risk professionals worldwide, 88% of those using AI apply it to document summarisation, and 85% use it for document review during investigations.</p> <ul> <li>White &amp; Case - Artificial intelligence in the compliance function</li> </ul> <p>McKinsey - The State of AI (2025) McKinsey reports that organisations leveraging generative AI in risk, legal, and compliance functions achieve 30-40% time savings on tasks such as document analysis and manual reviews.</p> <ul> <li>McKinsey - The State of AI: How organisations are rewiring to capture value</li> </ul>"},{"location":"blog/2026/02/15/the-hidden-cost-of-customer-support-why-agents-spend-more-time-typing-than-talking/","title":"The Hidden Cost of Customer Support: Why Agents Spend More Time Typing Than Talking","text":"<p>You call your energy provider. Something's wrong with your bill. The agent is friendly, asks the right questions, looks things up. Ten minutes later, it's sorted.</p> <p>What you don't see: that same agent then spends another eight minutes documenting the call. What was the issue. What was agreed. What follow-up is needed. All typed manually into a CRM system, while the next caller is already waiting.</p> <p>That's the reality for most service teams. Agents often spend more time on documentation than on the actual conversation. And when it gets busy, those notes get shorter, messier, or skipped entirely. The result: the next colleague who picks up the phone hears \"I don't have any record of that.\"</p> <p>Now imagine that summary just exists. Automatically. Within seconds after the call. Not perfect, but 90% complete - the issue, the agreement, the next step. The agent reviews it, adjusts if needed, done. Next caller.</p> <p>This isn't hypothetical. JetBlue already does it. They save nearly five minutes per chat on average. Over a single quarter, that adds up to 73,000 agent hours freed up for actual customer contact. Researchers from Stanford and MIT measured a 14% productivity gain at a large organisation - and 34% for newer employees, because they no longer struggle to document things they've only just learned.</p> <p>The point isn't that AI replaces the agent. The point is that the agent can finally do what you hired them for: listen, solve, and move on.</p>"},{"location":"blog/2026/02/15/the-hidden-cost-of-customer-support-why-agents-spend-more-time-typing-than-talking/#sources","title":"Sources","text":"<p>JetBlue - 73,000 agent hours per quarter, 280 seconds saved per chat BCG (2023). \"How Generative AI Is Already Transforming Customer Service.\"</p> <ul> <li>BCG - How Generative AI Is Already Transforming Customer Service</li> </ul> <p>BCG - 80% time savings on after-call summaries BCG/Microsoft webinar (2023). \"Reimagining Customer Service and Support with the Power of Generative AI.\" Reported via NoJitter.</p> <ul> <li>NoJitter - Using Generative AI to Improve Customer Experience</li> </ul> <p>Stanford/MIT - 14% productivity gain, 34% for newer employees Brynjolfsson, E., Li, D. &amp; Raymond, L. (2025). \"Generative AI at Work.\" The Quarterly Journal of Economics, 140(2), 889-942.</p> <ul> <li>The Quarterly Journal of Economics - Generative AI at Work</li> </ul> <p>Octopus Energy - 18% higher customer satisfaction with AI-drafted emails BCG (2023), same publication as JetBlue case.</p> <ul> <li>BCG - How Generative AI Is Already Transforming Customer Service</li> </ul> <p>Additional context BCG (2025). \"Unlocking Impact from Agentic AI in Customer Service.\"</p> <ul> <li>BCG - Unlocking Impact from AI Customer Service Ops</li> </ul>"},{"location":"blog/2026/02/28/fastrender-what-cursors-ai-browser-experiment-teaches-us-about-agentic-coding/","title":"FastRender: What Cursor's AI Browser Experiment Teaches Us About Agentic Coding","text":"<p>Cursor had hundreds of AI agents build a browser in a week. Three million lines of Rust. Six weeks later: one developer with one agent built the same thing in 20,000 lines. What does that tell us about multi-agent coding?</p> <p></p> <p>A note upfront: developments in AI move fast. The research I reference here dates from mid-2025 to early 2026. Claims that hold today may be outdated in a few months. I include dates for each study. Read with that context in mind.</p> <p>In mid-January, Michael Truell, CEO of Cursor, announced that hundreds of AI agents had built a web browser in one week [1]. Three million lines of Rust code. Thousands of files. A custom rendering engine with HTML parsing, CSS cascade, layout, text shaping and a JavaScript VM.</p> <p>Six weeks later, the dust has settled. A good moment to look at what we can learn from this. Both from the project itself and from the reactions it provoked.</p>"},{"location":"blog/2026/02/28/fastrender-what-cursors-ai-browser-experiment-teaches-us-about-agentic-coding/#what-happened","title":"What happened","text":"<p>Cursor engineer Wilson Lin started FastRender as a personal side project in November 2025 [2]. He wanted to test how well frontier models like Claude Opus 4.5 and GPT-5.1 handle complex tasks. A browser rendering engine was a good choice: very ambitious, but well specified through existing web standards. And you can visually see whether it works.</p> <p>When results with individual agents looked promising, it escalated into an official Cursor research project. Hundreds of GPT-5.2 agents (Cursor's own wording; some sources mention up to 2,000 [10]) worked together non-stop for almost a week. The architecture consisted of three roles. Planners explored the codebase and created tasks. Workers executed tasks and pushed commits. Judge agents evaluated per cycle whether work was good enough or needed to be redone. The WhatWG and CSS-WG web standards were included as git submodules, so agents could consult reference material [2].</p> <p>The result: over one million lines of Rust (three million according to the CEO on X), spread across thousands of files. Demos showed that simple websites like GitHub, Wikipedia and CNN rendered in a rudimentary way [2].</p>"},{"location":"blog/2026/02/28/fastrender-what-cursors-ai-browser-experiment-teaches-us-about-agentic-coding/#what-the-code-looks-like","title":"What the code looks like","text":"<p>When developers cloned the repo, problems started [4]. <code>cargo check</code> produced dozens of errors and about a hundred warnings. All CI runs on the main branch failed. Looking back through git history, there was not a single commit that compiled cleanly [4, 5].</p> <p>The \"from scratch\" claim also turned out to be more nuanced. The dependency list includes html5ever (Servo's HTML parser), cssparser (Servo's CSS parser) and rquickjs (a JavaScript runtime). These are core components from Mozilla's Servo browser engine [5]. Wilson Lin responded that the JS VM, DOM, paint systems and text pipeline were built as part of the project [6]. A Servo maintainer called the code a \"tangle of spaghetti\", but gave the backhanded compliment that at least it was not copied from existing implementations [7].</p> <p>The Dutch Software Improvement Group (SIG) conducted a formal analysis in February 2026 using their Sigrid platform [8]. The codebase corresponds to roughly 110 person-years of Rust development. The maintainability score is 1.3 out of 5, placing it in the bottom 5% of all systems SIG sees on the market. Architecture quality scores 2.1 out of 5. That indicates tightly coupled components and low modularity. Changes to FastRender take on average four times longer than in a four-star codebase [8].</p> <p>Cursor's blog post created the impression of a working prototype, but included no reproducible demo, no build instructions and no known-good commit [4].</p>"},{"location":"blog/2026/02/28/fastrender-what-cursors-ai-browser-experiment-teaches-us-about-agentic-coding/#what-it-cost","title":"What it cost","text":"<p>Estimates vary, but the picture is consistent: this was expensive. The Register estimated 10-20 trillion tokens and several million dollars [7]. A GitHub issue put the cost at 5-6 million dollars [9]. The Decoder mentioned costs in the high five to six figures [10].</p>"},{"location":"blog/2026/02/28/fastrender-what-cursors-ai-browser-experiment-teaches-us-about-agentic-coding/#what-others-did-since","title":"What others did since","text":"<p>Two weeks after FastRender, \"embedding-shapes\", the same developer who first critically examined Cursor's claims, published the project one-agent-one-browser [11]. In three days, this developer used a single Codex CLI agent to build 20,000 lines of Rust into a browser that successfully renders HTML and CSS. Without external Rust crate dependencies. Simon Willison installed the 1MB binary, tested it on his blog and was positively surprised [12].</p> <p>He also admitted: he had thought building a browser was the perfect problem to demonstrate massively parallel agent setups, because it could not be achieved in a few thousand lines of code by a single agent. Turns out it could [13]. That is an interesting finding in itself.</p> <p>In parallel, HiWave appeared, a privacy-first browser with \"RustKit\", also a custom engine in Rust. With pixel-perfect visual parity tests against Chrome 120 baselines [14].</p> <p>Cursor itself built a Windows emulator, a Java LSP implementation and an Excel clone alongside FastRender. All as test cases for GPT-5.2's agent capabilities [1].</p>"},{"location":"blog/2026/02/28/fastrender-what-cursors-ai-browser-experiment-teaches-us-about-agentic-coding/#what-the-research-says","title":"What the research says","text":"<p>This is where it gets most interesting for me. The studies I reference below date from March 2025 to January 2026. Given the pace of developments, it is worth weighing the date of each study.</p> <p>METR Time Horizons (March 2025, updated January 2026). Research institute METR showed that the duration of tasks AI agents can complete autonomously (with 50% reliability) is growing exponentially. The doubling time is approximately 7 months [15]. In the 2024-2025 period, this accelerated to every 4 months [16]. But there is an important nuance in how METR defines tasks: they must be coherent, self-contained units that cannot be trivially split. Solving a thousand separate one-hour problems is not a thousand-hour task but a one-hour task done a thousand times [15]. FastRender looks more like the latter: many small tasks in parallel, not one coherent whole.</p> <p>MIT Technology Review raised concerns about the METR graph in February 2026 [17]. The error margins are large. And the measurements are primarily based on coding tasks, not software development in the broader sense.</p> <p>METR Developer Productivity Study (July 2025). In a controlled experiment with 16 experienced open-source developers, developers using AI tools were 19% slower than without. While they believed they were 20% faster [18]. A perception gap of 39 percentage points. This does not mean AI is useless. It means that in July 2025, we were still learning how to use it effectively. Whether this has improved since is unknown. The researchers themselves acknowledge that learning effects may only become visible after hundreds of hours [18].</p> <p>Google DORA Report (2025). A 90% increase in AI adoption correlated with 9% more bugs, 91% more code review time and 154% larger pull requests [19]. That is not an argument against AI. It is a signal that how we use it matters.</p> <p>Multi-agent vs. single-agent. The Decoder reported in January 2026 that single agents achieve up to five times more successful tasks per 1,000 tokens than the most complex multi-agent architectures [10]. The one-agent-one-browser project fits that pattern: one agent plus one capable engineer produced a working result in three days [11].</p> <p>UC San Diego/Cornell (December 2025). Experienced developers do not \"vibe code\". They control. Professionals retain agency in software design, insist on fundamental quality attributes and deploy explicit control strategies to manage agent behaviour [19]. Stack Overflow's 2025 survey confirms: 72% of developers say vibe coding is not part of their professional work [19].</p> <p>METR: Algorithmic vs. Holistic Evaluation (August 2025). AI agents often produce functionally correct code that is not directly usable due to issues with test coverage, formatting and general code quality [20]. Automatic scoring as used by many benchmarks may overestimate real-world AI agent performance. This aligns with what we see in FastRender: code that looks like a browser at first glance, but does not compile.</p>"},{"location":"blog/2026/02/28/fastrender-what-cursors-ai-browser-experiment-teaches-us-about-agentic-coding/#what-we-can-learn-from-this","title":"What we can learn from this","text":"<p>FastRender is an experiment. An expensive experiment with clear shortcomings, but an experiment we can learn from. The same applies to the criticism it received.</p> <p>What it shows. AI agents can produce enormous amounts of code in a short time. The planner/worker/judge architecture is an interesting approach for future research. For well-specified domains with visual feedback loops, this produces usable results.</p> <p>Where it falls short. The code is in the bottom 5% for maintainability [8]. It barely compiles [4]. And one developer with one agent produced comparable work in three days, in 20,000 lines instead of 3 million [11]. More agents and more tokens are not a substitute for architectural insight.</p> <p>The practical lesson. The value of AI is not in unleashing agents on a problem. It is in orchestrating them well. That requires someone who knows which problems lend themselves to AI delegation, how to set up feedback loops and when to tighten the reins.</p> <p>The difference between FastRender and one-agent-one-browser is the difference between undirected AI and AI under the direction of a capable engineer. We are all learning how that works. Projects like FastRender, however imperfect, help with that.</p>"},{"location":"blog/2026/02/28/fastrender-what-cursors-ai-browser-experiment-teaches-us-about-agentic-coding/#references","title":"References","text":"<p>[1] Cursor, \"Scaling long-running autonomous coding\", 14 January 2026. https://cursor.com/blog/scaling-agents</p> <p>[2] S. Willison, \"FastRender: a browser built by thousands of parallel agents\" (including interview with Wilson Lin), 23 January 2026. https://simonw.substack.com/p/fastrender-a-browser-built-by-thousands</p> <p>[3] GitHub repository FastRender. https://github.com/wilsonzlin/fastrender</p> <p>[4] embedding-shapes, \"Cursor's latest browser experiment implied success without evidence\", January 2026. https://emsh.cat/cursor-implied-success-without-evidence/</p> <p>[5] EverydayAI Blog, \"Cursor AI Browser Can't Compile: Developers Call It 'AI Slop'\", 24 February 2026. https://everydayaiblog.com/cursor-ai-browser-cant-compile/</p> <p>[6] The Register, \"Cursor used agents to write a browser, proving AI can write shoddy code at scale\", 22 January 2026. https://www.theregister.com/2026/01/22/cursor_ai_wrote_a_browser/</p> <p>[7] The Register, \"Cursor is better at marketing than coding\" (opinion), 26 January 2026. https://www.theregister.com/2026/01/26/cursor_opinion/</p> <p>[8] Software Improvement Group, \"We analyzed the code of Cursor's AI-built browser FastRender\", February 2026. https://www.softwareimprovementgroup.com/blog/quality-of-fastrender/</p> <p>[9] GitHub Issue #115, \"AI slop lol\" (cost estimate), 28 January 2026. https://github.com/wilsonzlin/fastrender/issues/115</p> <p>[10] The Decoder, \"Frontier Radar #1: From chatbots to problem solvers\", January 2026. https://the-decoder.com/frontier-radar-1-from-chatbots-to-problem-solvers-the-state-of-ai-agents-in-2026/</p> <p>[11] GitHub repository one-agent-one-browser (embedding-shapes). https://github.com/embedding-shapes/one-agent-one-browser</p> <p>[12] S. Willison, \"One Human + One Agent = One Browser From Scratch\", 27 January 2026. https://simonwillison.net/2026/Jan/27/one-human-one-agent-one-browser/</p> <p>[13] Hacker News, \"Show HN: One Human + One Agent = One Browser From Scratch in 20K LOC\", January 2026. https://news.ycombinator.com/item?id=46779522</p> <p>[14] HiWave Browser, homepage with RustKit engine information. https://www.hiwavebrowser.com/</p> <p>[15] METR, \"Measuring AI Ability to Complete Long Tasks\", March 2025. https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/</p> <p>[16] The AI Digest, \"A new Moore's Law for AI agents\" (summary of METR data), 2025-2026. https://theaidigest.org/time-horizons</p> <p>[17] MIT Technology Review, \"This is the most misunderstood graph in AI\", 5 February 2026. https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/</p> <p>[18] METR, \"Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity\", July 2025. https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/</p> <p>[19] M. Mason, \"AI Coding Agents in 2026: Coherence Through Orchestration, Not Autonomy\", January 2026. Contains references to Google DORA Report 2025, UC San Diego/Cornell study (December 2025) and Stack Overflow survey 2025. https://mikemason.ca/writing/ai-coding-agents-jan-2026/</p> <p>[20] METR, \"Research Update: Algorithmic vs. Holistic Evaluation\", August 2025. https://metr.org/blog/2025-08-12-research-update-towards-reconciling-slowdown-with-time-horizons/</p> <p>Jan Keijzer is founder of Imperial Automation, an AI automation consultancy helping European businesses turn friction into flow. With a PhD in Nuclear Reactor Physics from TU Delft and 30+ years of software development experience, he helps organisations deploy AI effectively.</p>"},{"location":"blog/2026/02/07/from-nuclear-physics-to-ai-why-fusions-digital-twin-matters/","title":"From Nuclear Physics to AI: Why Fusion's Digital Twin Matters","text":"<p>I did my PhD in Nuclear Reactor Physics. Now I work with AI automation.</p> <p>So when I stumbled on a video about the Siemens keynote at CES 2026, I had to pay attention.</p> <p> Image: T. Henderson, CFS/MIT-PSFC, 2020</p> <p>Commonwealth Fusion Systems is building SPARC \u2014 a compact fusion reactor designed to achieve what has been the holy grail of nuclear fusion for decades: producing more energy than it consumes. Generations of physicists have worked toward this moment.</p> <p>But what really got me: they're partnering with Siemens and Nvidia to build an AI-powered digital twin of the reactor.</p> <p>Not just a 3D model. A virtual copy that runs alongside the real machine, ingests live data, tests hypotheses, and compresses years of experimentation into weeks.</p> <p>Siemens NX for the engineering data. Nvidia Omniverse for the simulation. AI tying it all together.</p> <p>What fascinates me is how broad AI's reach is becoming. One day it's helping crack nuclear fusion. The next, it's streamlining everyday business operations. The problems look nothing alike, but the underlying ability \u2014 to simulate, learn, and iterate faster than we ever could \u2014 is the same.</p> <p>AI is already reshaping how we work. That's not going to slow down. I'm glad I get to help people and organisations make that shift in a way that actually works for them.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/","title":"Automating GitHub Workflows with Custom Claude Code Skills","text":"<p>If you've ever managed a large GitHub issue with multiple sub-tasks, you know the drill: create sub-issues one by one, set up a tracking PR, manually update status tables, ensure all the <code>Closes #XXX</code> statements are in sync. It's tedious, error-prone, and takes 20-30 minutes of pure overhead for each large feature.</p> <p>What if you could compress that entire workflow into a single command that takes 2 minutes?</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#the-problem-github-issue-management-takes-too-much-time","title":"The Problem: GitHub Issue Management Takes Too Much Time","text":"<p>Here's what managing a complex feature traditionally looks like:</p> <ol> <li>Initial Decomposition (10-15 minutes):</li> <li>Read through the parent issue</li> <li>Manually create 3-5 sub-issues with proper formatting</li> <li>Set up a tracking PR with a status table</li> <li>Add <code>Closes #XXX</code> statements for each sub-issue</li> <li> <p>Link everything together</p> </li> <li> <p>Ongoing Maintenance (5-10 minutes per update):</p> </li> <li>Check which sub-issues are complete</li> <li>Update the status table in the tracking PR</li> <li>Verify all PRs are linked correctly</li> <li>Add new sub-issues when bugs are discovered</li> <li> <p>Keep <code>Closes</code> statements synchronized</p> </li> <li> <p>Final Merge (5 minutes):</p> </li> <li>Double-check all sub-issues are referenced</li> <li>Ensure nothing falls through the cracks</li> <li>Merge and hope GitHub auto-closes everything</li> </ol> <p>Total overhead per feature: 30-45 minutes of pure administrative work. Multiply that by 10 features per month, and you've lost a full workday to GitHub bureaucracy.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#the-solution-systematic-ai-augmentation-through-custom-skills","title":"The Solution: Systematic AI Augmentation Through Custom Skills","text":"<p>Instead of fighting with GitHub's UI or writing one-off scripts, I built a suite of Claude Code skills that encode best practices into reusable automation. These skills transform complex workflows into simple commands.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#what-are-claude-code-skills","title":"What Are Claude Code Skills?","text":"<p>Claude Code is Anthropic's CLI tool that brings Claude's AI capabilities directly into your terminal. Skills are markdown-based extensions that teach Claude new workflows. Think of them as specialized functions that Claude can execute on your behalf.</p> <p>The key insight: AI augmentation requires systematic tooling, not ad-hoc prompts. Skills capture process knowledge and make it repeatable.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#the-skills-a-complete-issue-management-system","title":"The Skills: A Complete Issue Management System","text":"<p>I built six interconnected skills that handle the entire lifecycle of complex GitHub issues:</p> <p></p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#the-workflow-in-action","title":"The Workflow in Action","text":""},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#1-decompose-break-down-large-issues","title":"1. <code>/decompose</code> - Break Down Large Issues","text":"<p>The starting point for any complex feature. This skill analyzes a parent issue and intelligently breaks it into manageable sub-issues.</p> <pre><code>/decompose 723\n</code></pre> <p>What it does:</p> <ol> <li>Fetches the issue using <code>gh issue view</code></li> <li>Analyzes the structure (phases, checklists, dependencies)</li> <li>Proposes a breakdown with a clear table</li> <li>Creates sub-issues after confirmation</li> <li>Sets up a draft tracking PR with status table</li> <li>Links everything together with <code>Closes</code> statements</li> </ol> <p>Example output:</p> <pre><code>## Proposed Sub-Issues for #723: Stripe Payment Provider\n\n| #   | Sub-Issue Title                    | Depends On | Scope    |\n| --- | ---------------------------------- | ---------- | -------- |\n| 1   | Phase 1: Payment Abstraction Layer | -          | Backend  |\n| 2   | Phase 2: Stripe Integration        | #1         | Backend  |\n| 3   | Phase 3: Frontend Payment UI       | #1, #2     | Frontend |\n\nCreate these sub-issues? (A/B/C)\n</code></pre> <p>Time saved: 15 minutes \u2192 2 minutes</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#2-bug-create-bug-sub-issues","title":"2. <code>/bug</code> - Create Bug Sub-Issues","text":"<p>Found a bug while implementing a sub-issue? Don't break your flow.</p> <pre><code># On branch issue-724-abstraction-layer\n/bug \"Webhook signature verification fails in test mode\"\n</code></pre> <p>What it does:</p> <ol> <li>Auto-detects parent issue from branch name (<code>issue-724-*</code>)</li> <li>Creates a bug issue with proper prefix: <code>\ud83d\udc1b [Parent #724] Bug: Webhook signature verification fails</code></li> <li>Adds it to the tracking PR</li> <li>Updates <code>Closes</code> statements automatically</li> </ol> <p>Time saved: 5 minutes \u2192 30 seconds</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#3-update-tracking-refresh-progress-status","title":"3. <code>/update-tracking</code> - Refresh Progress Status","text":"<p>After merging a few sub-issue PRs, update the tracking PR to reflect current progress.</p> <pre><code>/update-tracking 727\n</code></pre> <p>What it does:</p> <ol> <li>Fetches status of all sub-issues</li> <li>Checks for merged PRs linked to each sub-issue</li> <li>Updates status emojis (\u23f3 Pending \u2192 \u2705 Complete)</li> <li>Recalculates progress percentage</li> </ol> <p>Before: <pre><code>| #   | Sub-Issue                 | Status    | PR  |\n| --- | ------------------------- | --------- | --- |\n| 1   | #724 - Abstraction Layer  | \u23f3 Pending | -   |\n| 2   | #725 - Stripe Integration | \u23f3 Pending | -   |\n\nProgress: 0/2 (0%)\n</code></pre></p> <p>After: <pre><code>| #   | Sub-Issue                 | Status        | PR   |\n| --- | ------------------------- | ------------- | ---- |\n| 1   | #724 - Abstraction Layer  | \u2705 Complete    | #731 |\n| 2   | #725 - Stripe Integration | \ud83d\udd04 In Progress | #732 |\n\nProgress: 1/2 (50%)\n</code></pre></p> <p>Time saved: 5 minutes \u2192 1 minute</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#4-extend-add-more-sub-issues","title":"4. <code>/extend</code> - Add More Sub-Issues","text":"<p>Realized you need to tackle another phase? Extend the existing tracking PR instead of creating chaos.</p> <pre><code>/extend 723\n</code></pre> <p>What it does:</p> <ol> <li>Finds the existing tracking PR</li> <li>Analyzes which tasks don't have sub-issues yet</li> <li>Proposes new sub-issues</li> <li>Adds them to the tracking PR and updates <code>Closes</code> statements</li> </ol> <p>Key difference from <code>/decompose</code>: Works with existing structure, doesn't create a new PR.</p> <p>Time saved: 10 minutes \u2192 2 minutes</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#5-sync-closes-ensure-complete-issue-closure","title":"5. <code>/sync-closes</code> - Ensure Complete Issue Closure","text":"<p>Before merging, verify all sub-issues will auto-close when the tracking PR is merged.</p> <pre><code>/sync-closes 727\n</code></pre> <p>What it does:</p> <ol> <li>Extracts all issue numbers from the status table</li> <li>Compares with <code>Closes #XXX</code> statements in PR body</li> <li>Identifies missing statements</li> <li>Adds them after confirmation</li> </ol> <p>Example: <pre><code>Current Closes: #723, #724, #725\nFound in table: #723, #724, #725, #730 (bug)\n\nMissing: #730\n\nAdd \"Closes #730\" to PR? (y/n)\n</code></pre></p> <p>Time saved: 5 minutes \u2192 1 minute</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#6-help-issues-quick-reference","title":"6. <code>/help-issues</code> - Quick Reference","text":"<p>Forgot the syntax? Get a quick reference card.</p> <pre><code>/help-issues\n</code></pre> <p>Returns the complete workflow guide with examples.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#bonus-workflow-skills-for-complete-automation","title":"Bonus: Workflow Skills for Complete Automation","text":"<p>Beyond issue management, I also created skills for the implementation workflow:</p> <ul> <li><code>/implement &lt;issue&gt;</code> - Full guided workflow: fetch issue, plan, create branch, implement, test, create PR</li> <li><code>/cleanup</code> - Post-merge cleanup: checkout base branch, fetch, pull, delete merged branch</li> <li><code>/finish &lt;issue&gt;</code> - Complete workflow: commit, close issue, merge to base, cleanup</li> </ul> <p>These encode mission-critical discipline into every step, ensuring nothing falls through the cracks.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#real-impact-the-numbers","title":"Real Impact: The Numbers","text":"<p>Let's quantify the time savings across a typical month:</p> Task Before After Per Month Saved Decompose 5 features 15 min \u00d7 5 2 min \u00d7 5 75 min vs 10 min 65 min Update tracking 20\u00d7 5 min \u00d7 20 1 min \u00d7 20 100 min vs 20 min 80 min Create 10 bug issues 5 min \u00d7 10 0.5 min \u00d7 10 50 min vs 5 min 45 min Sync before merge 5\u00d7 5 min \u00d7 5 1 min \u00d7 5 25 min vs 5 min 20 min Extend tracking 3\u00d7 10 min \u00d7 3 2 min \u00d7 3 30 min vs 6 min 24 min <p>Total monthly savings: 234 minutes (3.9 hours)</p> <p>But the real value isn't just time\u2014it's consistency. Every decomposition follows the same structure. Every tracking PR has the same format. Every <code>Closes</code> statement is synchronized. Zero human error.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#how-it-works-under-the-hood","title":"How It Works Under the Hood","text":"<p>Each skill is a markdown file in <code>~/.claude/skills/&lt;skill-name&gt;/SKILL.md</code> with three key sections:</p> <ol> <li> <p>Metadata (YAML frontmatter): <pre><code>---\nname: decompose\ndescription: Decompose a large GitHub issue into sub-issues\nargument-hint: &lt;issue-number&gt;\nuser-invocable: true\n---\n</code></pre></p> </li> <li> <p>Workflow Instructions: <pre><code>## Workflow\n\n### Step 1: Fetch and Analyze\n```bash\ngh issue view $ARGUMENTS --json title,body,labels\n</code></pre> Analyze phases, dependencies, logical groupings...</p> </li> </ol>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#step-2-propose-breakdown","title":"Step 2: Propose Breakdown","text":"<p>Present table to user with A/B/C options... <pre><code>3. **Error Handling &amp; Best Practices:**\n```markdown\n## Important Notes\n- Always ask before creating\n- Preserve original content\n- Use consistent naming: `issue-[number]-[feature]`\n</code></pre></p> <p>When you invoke <code>/decompose 723</code>, Claude: 1. Loads the skill prompt 2. Substitutes <code>$ARGUMENTS</code> with <code>723</code> 3. Executes the workflow step-by-step 4. Uses <code>gh</code> CLI for GitHub operations 5. Asks for confirmation at critical points</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#lessons-learned","title":"Lessons Learned","text":""},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#what-worked","title":"What Worked","text":"<p>1. Encoding best practices directly in skills</p> <p>Instead of remembering to add <code>Closes</code> statements, the skill does it automatically. Instead of manually formatting status tables, the skill uses a template.</p> <p>2. Confirmation gates at the right places</p> <p>Skills ask for user confirmation before creating issues/PRs, but automate everything else. This balances control with efficiency.</p> <p>3. Smart defaults with explicit overrides</p> <p>Branch name detection auto-extracts issue numbers (<code>issue-724-*</code> \u2192 <code>#724</code>), but you can always provide explicit parameters.</p> <p>4. Composable workflows</p> <p>Skills work independently but integrate seamlessly. <code>/bug</code> automatically updates the tracking PR created by <code>/decompose</code>.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#what-was-challenging","title":"What Was Challenging","text":"<p>1. Handling edge cases gracefully</p> <p>What if the tracking PR doesn't exist? What if the branch name doesn't follow conventions? The skills need defensive checks without becoming brittle.</p> <p>2. Balancing automation with transparency</p> <p>Users need to see what's happening (especially with GitHub API calls), but too much output is noise. I settled on showing key operations with clear progress indicators.</p> <p>3. GitHub CLI quirks</p> <p>The <code>gh</code> CLI is powerful but has subtle behaviors (like how it handles multi-line PR bodies). Skills need to use heredocs and proper escaping.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#why-this-matters","title":"Why This Matters","text":"<p>This project embodies what I mean by AI augmentation for mission-critical systems:</p> <ol> <li>Systematic, not ad-hoc - Skills capture repeatable processes, not one-off prompts</li> <li>Reliable and predictable - Same input always produces same output</li> <li>Human-in-the-loop - Automation handles tedium, humans make decisions</li> <li>Fail-safe design - Confirmation gates prevent destructive operations</li> </ol> <p>This is the same discipline I apply when architecting AI systems for finance, healthcare, and defense clients\u2014but scaled down to developer productivity.</p> <p>The meta-lesson: Effective AI augmentation requires treating automation itself as mission-critical infrastructure. These skills aren't clever hacks; they're maintainable, testable, documented tools.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#try-it-yourself","title":"Try It Yourself","text":"<p>Want to build your own Claude Code skills? Here's how to start:</p> <ol> <li> <p>Install Claude Code: Follow the instructions at claude.com/product/claude-code</p> </li> <li> <p>Create a skill directory: <pre><code>mkdir -p ~/.claude/skills/my-skill\n</code></pre></p> </li> <li> <p>Write a skill file (<code>~/.claude/skills/my-skill/SKILL.md</code>): <pre><code>---\nname: my-skill\ndescription: What your skill does\nuser-invocable: true\n---\n\n# My Skill\n\nHelp the user accomplish [specific task].\n\n## Input\nThe user provides: `$ARGUMENTS`\n\n## Workflow\n1. Do this\n2. Then that\n3. Finally this\n</code></pre></p> </li> <li> <p>Restart Claude Code to reload skills</p> </li> <li> <p>Test it: <pre><code>/my-skill some-argument\n</code></pre></p> </li> </ol> <p>The complete source for my issue management skills is available in my <code>~/.claude/skills/</code> directory. Check the README.md for detailed documentation.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#get-the-skills","title":"Get the Skills","text":"<p>All six issue management skills plus the workflow automation skills are now available as open source:</p> <p>View on GitHub \u2192</p> <p>The repository includes:</p> <ul> <li>Complete skill source code for all 9 skills</li> <li>Installation instructions</li> <li>Usage examples and demos</li> <li>Best practices guide</li> </ul>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#whats-next","title":"What's Next?","text":"<p>I'm exploring skills for:</p> <ul> <li>Code review automation - Extract common patterns from review feedback and apply them systematically</li> <li>Migration workflows - Multi-step codebase migrations with checkpoints and rollback</li> <li>Documentation generation - Auto-generate API docs from code with intelligent summaries</li> </ul> <p>The potential for AI augmentation through systematic tooling is enormous. We're just scratching the surface.</p>"},{"location":"blog/2026/01/26/automating-github-workflows-with-custom-claude-code-skills/#get-in-touch","title":"Get in Touch","text":"<p>If you're interested in AI augmentation for your team's workflows\u2014or need help architecting AI systems with mission-critical reliability\u2014let's talk.</p> <p>I'd also love to hear about the workflows you'd automate if you had the right tools. What takes 30 minutes today that could take 2 minutes tomorrow?</p> <p>Want to discuss your AI automation challenges? Schedule a call or connect on LinkedIn.</p>"},{"location":"experience/","title":"Professional Experience","text":"<p>Over three decades, I've built systems where failure isn't an option\u2014from life-safety healthcare platforms to spacecraft systems, from financial trading infrastructure to defense applications. Each role shaped my approach to reliability, scale, and mission-critical engineering.</p> <p>These experiences inform how I approach AI automation today: building systems that businesses can depend on, architecting for growth, and maintaining the rigor that mission-critical work demands.</p> <ul> <li> <p> Zintouch - Healthcare Alarm Systems</p> <p>Lead Developer scaling 24/7 life-safety systems through 100% YoY growth, from 5 to 50+ employees. Zero-downtime upgrades for systems where failure could cost lives.</p> <p>Read more </p> </li> <li> <p> DirectorInsight - Financial SaaS</p> <p>Lead Developer building global financial reporting infrastructure, scaling 24/7 operations from startup to 50 employees with year-over-year user base doubling.</p> <p>Read more </p> </li> <li> <p> ABN AMRO - Trading Systems</p> <p>Banking sector trading and investment systems with financial penalties for downtime. Where missed orders cost real money and market opportunities vanish in seconds.</p> <p>Read more </p> </li> <li> <p> ESA, TNO &amp; Atos - Aerospace &amp; Defense</p> <p>Spacecraft and defense systems where failure isn't an option. Once in space, there are no repairs\u2014this background shapes every reliability decision I make.</p> <p>Read more </p> </li> </ul>"},{"location":"experience/#why-this-background-matters-for-your-automation","title":"Why This Background Matters for Your Automation","text":"<p>When you hire someone to automate critical business processes, you need confidence the systems will actually work. My mission-critical background means:</p> <ul> <li>Reliability by design: Three decades building systems that can't fail translates to automation you can trust</li> <li>Scale without breaking: I've supported 100% YoY growth\u2014your automation will grow with your business</li> <li>Zero-downtime mindset: Learned from sectors with financial and life-safety penalties for outages</li> <li>Enterprise rigor: Security, compliance, and audit trails aren't afterthoughts\u2014they're foundational</li> </ul> <ul> <li> <p> Ready to apply this experience to your challenges?</p> <p>Let's discuss how mission-critical engineering discipline can transform your automation initiatives.</p> <p>Book a Free Call </p> </li> </ul>"},{"location":"experience/abn-amro/","title":"ABN AMRO - Trading &amp; Investment Systems","text":"<p> Back to Experience</p>"},{"location":"experience/abn-amro/#company-context","title":"Company Context","text":"<p>ABN AMRO, one of the Netherlands' largest banks, operates trading and investment platforms where milliseconds matter and downtime carries financial penalties. Through Atos Origin, I contributed to systems where reliability wasn't just desirable\u2014it was contractually required with monetary consequences for failures.</p>"},{"location":"experience/abn-amro/#role-responsibility","title":"Role &amp; Responsibility","text":"<p>Developer (via Atos Origin) - Contributing to trading and investment system development for banking operations.</p>"},{"location":"experience/abn-amro/#the-stakes-when-downtime-has-dollar-signs","title":"The Stakes: When Downtime Has Dollar Signs","text":"<p>Trading systems exist in an environment where failure has immediate financial impact:</p> <ul> <li>Missed trades represent lost opportunities that can't be recovered</li> <li>Market conditions change in seconds\u2014delays cost money</li> <li>Regulatory requirements demand complete audit trails</li> <li>Financial penalties apply when systems fail to meet uptime SLAs</li> <li>Client trust erodes quickly when trading platforms become unreliable</li> </ul>"},{"location":"experience/abn-amro/#key-insights","title":"Key Insights","text":""},{"location":"experience/abn-amro/#high-stakes-reliability","title":"High-Stakes Reliability","text":"<p>Banking sector trading taught me that system reliability isn't just a technical concern\u2014it's a business-critical requirement with direct financial consequences. When your SLA includes penalty clauses, you develop a particular respect for monitoring, redundancy, and failover strategies.</p>"},{"location":"experience/abn-amro/#real-time-performance-requirements","title":"Real-Time Performance Requirements","text":"<p>Financial markets don't wait. Systems must process transactions with minimal latency while maintaining data consistency. This environment demands careful architecture where performance and correctness both matter.</p>"},{"location":"experience/abn-amro/#comprehensive-audit-requirements","title":"Comprehensive Audit Requirements","text":"<p>Banking regulations require complete traceability. Every action, decision, and transaction must be logged and auditable. Building this rigor into systems from the start is easier than retrofitting it later.</p>"},{"location":"experience/abn-amro/#risk-management-mindset","title":"Risk Management Mindset","text":"<p>Working in banking infrastructure teaches you to think about failure modes systematically. What happens if this component fails? What if two components fail simultaneously? How do we detect problems before clients do?</p>"},{"location":"experience/abn-amro/#technologies","title":"Technologies","text":"<ul> <li>Domain: Trading systems, investment platforms</li> <li>Environment: Banking sector with strict regulatory requirements</li> <li>Focus: High availability, real-time processing, audit compliance</li> </ul>"},{"location":"experience/abn-amro/#what-i-learned","title":"What I Learned","text":"<p>Banking systems teach you that reliability has a price tag: When downtime costs real money through penalty clauses, reliability stops being an abstract goal and becomes a concrete business requirement. This experience shaped how I evaluate tradeoffs between features and stability.</p> <p>The banking sector's regulatory environment also demonstrated the value of building compliance and audit capabilities into systems from the beginning. Retrofitting these capabilities later is expensive and risky.</p>"},{"location":"experience/abn-amro/#how-this-experience-applies-to-your-business","title":"How This Experience Applies to Your Business","text":"<p>Banking sector work taught me to build automation where stakes are high:</p> <ul> <li>Reliability as requirement: Systems designed with consequences in mind</li> <li>Performance under pressure: Maintaining speed without sacrificing correctness</li> <li>Audit-ready from day one: Compliance built into architecture</li> <li>Risk-aware engineering: Planning for failure scenarios systematically</li> </ul> <ul> <li> <p> Need automation you can bet on?</p> <p>Let's discuss how banking sector discipline can strengthen your business systems.</p> <p>Book a Free Call </p> </li> </ul> <p> Back to Experience Overview</p>"},{"location":"experience/directorinsight/","title":"DirectorInsight - Financial Reporting SaaS","text":"<p> Back to Experience</p>"},{"location":"experience/directorinsight/#company-context","title":"Company Context","text":"<p>DirectorInsight provided financial reporting and analysis SaaS to international enterprises. CFOs and financial controllers depended on the platform for management reporting, financial consolidation, and business intelligence across multiple entities and currencies. With clients spanning different time zones, the infrastructure operated 24/7 with continuous uptime expectations.</p>"},{"location":"experience/directorinsight/#role-responsibility","title":"Role &amp; Responsibility","text":"<p>Lead Developer - Full-stack architecture and development for enterprise financial SaaS platform.</p>"},{"location":"experience/directorinsight/#the-challenge-global-scale-meets-financial-precision","title":"The Challenge: Global Scale Meets Financial Precision","text":"<p>Financial reporting doesn't allow for approximations\u2014numbers must be exact, audit trails complete, and availability constant. The company grew from a small team to 50 employees, with the user base doubling year-over-year. The technical challenge combined:</p> <ul> <li>Global 24/7 infrastructure across time zones</li> <li>Complex financial calculations and consolidations</li> <li>Multi-tenant architecture with data isolation</li> <li>Regulatory compliance and audit requirements</li> <li>Enterprise integration with various ERP systems</li> <li>Performance at scale without compromising accuracy</li> </ul>"},{"location":"experience/directorinsight/#key-achievements","title":"Key Achievements","text":""},{"location":"experience/directorinsight/#247-global-infrastructure","title":"24/7 Global Infrastructure","text":"<p>Built and maintained continuous uptime for international financial clients operating across different time zones. When European controllers start their day as American finance teams finish theirs, downtime isn't an option.</p>"},{"location":"experience/directorinsight/#hypergrowth-support","title":"Hypergrowth Support","text":"<p>Architected systems that supported 100% year-over-year user base growth without performance degradation. Financial reporting often involves complex calculations across thousands of records\u2014scale required careful optimization.</p>"},{"location":"experience/directorinsight/#enterprise-architecture","title":"Enterprise Architecture","text":"<p>Designed multi-tenant infrastructure with proper data isolation, ensuring each client's financial data remained secure and compliant with regulatory requirements.</p>"},{"location":"experience/directorinsight/#financial-precision","title":"Financial Precision","text":"<p>Implemented robust calculation engines for financial consolidation, currency conversion, and management reporting. In finance, being \"close enough\" isn't acceptable\u2014numbers must be exactly right.</p>"},{"location":"experience/directorinsight/#integration-layer","title":"Integration Layer","text":"<p>Built connectors to various ERP systems and financial platforms, handling the heterogeneity of enterprise finance infrastructure while maintaining data consistency.</p>"},{"location":"experience/directorinsight/#technologies","title":"Technologies","text":"<ul> <li>Backend: PHP, MySQL, enterprise architecture patterns</li> <li>Infrastructure: 24/7 global deployment with monitoring</li> <li>Integration: ERP system APIs, financial data import/export</li> <li>Compliance: Audit trail logging, data security, regulatory requirements</li> </ul>"},{"location":"experience/directorinsight/#business-impact","title":"Business Impact","text":"<p>The technical foundation enabled DirectorInsight to scale from startup to 50-employee company serving international enterprises. By maintaining reliability and performance during rapid growth, the platform supported the business's expansion into new markets and larger enterprise clients.</p>"},{"location":"experience/directorinsight/#what-i-learned","title":"What I Learned","text":"<p>Financial systems teach you that precision and reliability are inseparable: You can't have one without the other. A fast system that occasionally produces wrong numbers is worthless. A precise system that's unavailable when finance teams need it is equally problematic.</p> <p>Global operations across time zones mean traditional \"maintenance windows\" disappear\u2014someone is always working. This pushed architectural decisions toward zero-downtime deployments and robust monitoring.</p> <p>Enterprise clients have high expectations and low tolerance for issues. Meeting those expectations while scaling rapidly required disciplined engineering, comprehensive testing, and proactive monitoring.</p>"},{"location":"experience/directorinsight/#how-this-experience-applies-to-your-business","title":"How This Experience Applies to Your Business","text":"<p>Financial SaaS taught me to build automation that enterprises can trust:</p> <ul> <li>Precision under pressure: Systems that remain accurate at scale</li> <li>Always-on reliability: Global operations without maintenance windows</li> <li>Enterprise security: Data isolation and compliance built into architecture</li> <li>Scale without compromising quality: Growth that doesn't sacrifice accuracy or availability</li> </ul> <ul> <li> <p> Need enterprise-grade automation?</p> <p>Let's discuss how financial sector discipline can elevate your automation initiatives.</p> <p>Book a Free Call </p> </li> </ul> <p> Back to Experience Overview</p>"},{"location":"experience/esa-defense/","title":"ESA, TNO &amp; Atos Origin - Aerospace &amp; Defense","text":"<p> Back to Experience</p>"},{"location":"experience/esa-defense/#company-context","title":"Company Context","text":"<p>Through TNO (Netherlands Organization for Applied Scientific Research) and Atos Origin, I contributed to spacecraft systems for the European Space Agency (ESA) and defense applications. These sectors represent the ultimate test of engineering discipline: once hardware launches into space, there are no repair visits. Software must work correctly the first time, every time.</p>"},{"location":"experience/esa-defense/#role-responsibility","title":"Role &amp; Responsibility","text":"<p>Developer - Contributing to spacecraft and defense system development through government and aerospace contractors.</p>"},{"location":"experience/esa-defense/#the-reality-no-second-chances","title":"The Reality: No Second Chances","text":"<p>Aerospace and defense work operates under constraints that fundamentally shape engineering approach:</p> <ul> <li>Spacecraft systems: Once in orbit, there's no way to physically repair hardware failures</li> <li>Defense applications: Lives and national security depend on system reliability</li> <li>Long operational lifetimes: Systems must function for years or decades without maintenance</li> <li>Harsh environments: Radiation, extreme temperatures, vibration\u2014conditions that break consumer hardware</li> <li>Rigorous testing requirements: Failure analysis, redundancy planning, comprehensive validation</li> </ul>"},{"location":"experience/esa-defense/#key-insights","title":"Key Insights","text":""},{"location":"experience/esa-defense/#design-for-zero-touch-operations","title":"Design for Zero-Touch Operations","text":"<p>When you can't send a technician, systems must handle failures gracefully, automatically recover when possible, and provide clear diagnostics for remote intervention. This mindset\u2014designing for minimal human intervention\u2014applies directly to modern automation.</p>"},{"location":"experience/esa-defense/#test-everything-assume-nothing","title":"Test Everything, Assume Nothing","text":"<p>Aerospace testing regimens go far beyond \"it works on my machine.\" Every failure mode must be analyzed. Every edge case explored. Every assumption validated. This rigor becomes instinctive and carries over into all engineering work.</p>"},{"location":"experience/esa-defense/#redundancy-and-fallbacks","title":"Redundancy and Fallbacks","text":"<p>Single points of failure are unacceptable. Critical systems need backup paths, graceful degradation, and well-defined failure modes. Defense and aerospace engineering teaches you to think systematically about what happens when things go wrong.</p>"},{"location":"experience/esa-defense/#documentation-as-discipline","title":"Documentation as Discipline","text":"<p>In sectors with decades-long operational lifetimes and high personnel turnover, comprehensive documentation isn't optional. Future engineers must understand design decisions, failure modes, and system behavior without access to original developers.</p>"},{"location":"experience/esa-defense/#the-once-in-space-no-repairs-principle","title":"The \"Once in Space, No Repairs\" Principle","text":"<p>This phrase captures the essence of aerospace engineering discipline: you must get it right before launch. While modern software allows for updates and patches, the underlying principle remains valuable\u2014build systems that work correctly from deployment, not systems that require constant intervention.</p>"},{"location":"experience/esa-defense/#technologies","title":"Technologies","text":"<ul> <li>Domain: Spacecraft systems (ESA), defense applications (TNO)</li> <li>Environment: Mission-critical with extreme reliability requirements</li> <li>Focus: Redundancy, failure analysis, comprehensive testing, long-term operations</li> </ul>"},{"location":"experience/esa-defense/#what-i-learned","title":"What I Learned","text":"<p>Aerospace and defense teach you that perfect isn't optional: In most software development, you can release with known bugs and patch them later. In spacecraft systems, that approach doesn't work. This background instilled a discipline about correctness, testing, and failure planning that shapes everything I build.</p> <p>The experience also taught humility. When you've worked on systems where smart engineers still encountered unexpected failures after rigorous testing, you learn to respect complexity and never assume \"it should work.\"</p>"},{"location":"experience/esa-defense/#how-this-experience-applies-to-your-business","title":"How This Experience Applies to Your Business","text":"<p>Aerospace and defense work taught me to build automation with mission-critical discipline:</p> <ul> <li>Right the first time: Design for correctness, not continuous patching</li> <li>Failure planning: Systematic thinking about what goes wrong and how to handle it</li> <li>Minimal intervention: Systems that operate reliably without constant attention</li> <li>Long-term thinking: Building for operational life, not just initial deployment</li> </ul> <p>While your business automation doesn't face space radiation or battlefield conditions, the engineering principles still apply. Building systems that work reliably, handle failures gracefully, and require minimal intervention creates business value whether you're processing documents or managing spacecraft.</p> <ul> <li> <p> Need mission-critical reliability?</p> <p>Let's discuss how aerospace discipline can elevate your automation systems.</p> <p>Book a Free Call </p> </li> </ul> <p> Back to Experience Overview</p>"},{"location":"experience/zintouch/","title":"Zintouch - Healthcare Alarm Systems","text":"<p> Back to Experience</p>"},{"location":"experience/zintouch/#company-context","title":"Company Context","text":"<p>Zintouch provided 24/7 alarm systems for elderly care facilities across the Netherlands. When a resident pressed an emergency button, staff needed immediate alerts\u2014downtime could literally cost lives. The platform handled alarm routing, staff scheduling, capacity management, and integration with healthcare infrastructure.</p>"},{"location":"experience/zintouch/#role-responsibility","title":"Role &amp; Responsibility","text":"<p>Lead Developer - Full-stack development and architecture for mission-critical healthcare platform.</p>"},{"location":"experience/zintouch/#the-challenge-hypergrowth-meets-life-safety-requirements","title":"The Challenge: Hypergrowth Meets Life-Safety Requirements","text":"<p>The company scaled rapidly from 5 to 50+ employees, with the user base doubling year-over-year. Every new care facility added hundreds of residents to the system, each representing a potential life-safety event. The technical challenge wasn't just growth\u2014it was maintaining 24/7 reliability while:</p> <ul> <li>Adding new alarm system integrations</li> <li>Building management dashboards for capacity planning</li> <li>Integrating with third-party healthcare systems</li> <li>Deploying feature updates without service interruption</li> <li>Ensuring GDPR compliance for sensitive medical data</li> </ul>"},{"location":"experience/zintouch/#key-achievements","title":"Key Achievements","text":""},{"location":"experience/zintouch/#zero-downtime-architecture","title":"Zero-Downtime Architecture","text":"<p>Engineered deployment strategies that allowed continuous feature delivery without interrupting alarm processing. When lives depend on your system, \"scheduled maintenance windows\" aren't an option.</p>"},{"location":"experience/zintouch/#scale-infrastructure","title":"Scale Infrastructure","text":"<p>Supported 100% year-over-year user growth through database optimization, caching strategies, and architectural refinements. Built monitoring to catch performance degradation before it impacted response times.</p>"},{"location":"experience/zintouch/#management-dashboards","title":"Management Dashboards","text":"<p>Created capacity planning tools that helped operations teams understand workload distribution, predict staffing needs, and optimize resource allocation across facilities.</p>"},{"location":"experience/zintouch/#third-party-integrations","title":"Third-Party Integrations","text":"<p>Integrated diverse alarm systems and healthcare platforms, building robust error handling and fallback mechanisms. Healthcare infrastructure is heterogeneous\u2014reliability required planning for every edge case.</p>"},{"location":"experience/zintouch/#expanded-alarm-support","title":"Expanded Alarm Support","text":"<p>Extended the platform to support new alarm system types and protocols, maintaining backwards compatibility while enabling business growth into new markets.</p>"},{"location":"experience/zintouch/#technologies","title":"Technologies","text":"<ul> <li>Backend: PHP, MySQL, REST APIs</li> <li>Infrastructure: 24/7 production environment with monitoring and alerting</li> <li>Integration: Healthcare system APIs, alarm hardware protocols</li> <li>Compliance: GDPR-compliant data handling for medical information</li> </ul>"},{"location":"experience/zintouch/#business-impact","title":"Business Impact","text":"<p>The technical foundation supported Zintouch's growth from small startup to 50+ employee company serving care facilities across the Netherlands. By maintaining reliability during hypergrowth, the platform enabled the business to confidently take on new clients without technical limitations.</p>"},{"location":"experience/zintouch/#what-i-learned","title":"What I Learned","text":"<p>Life-safety systems teach you things no amount of theory can: The feeling when an alarm system processes thousands of real emergencies reinforces that reliability isn't a feature\u2014it's the foundation. You learn to question every assumption, plan for unlikely failures, and build systems that gracefully handle the unexpected.</p> <p>This experience shaped my entire approach to software engineering. When you've built systems where downtime has life-or-death consequences, you bring that discipline to everything else you build.</p>"},{"location":"experience/zintouch/#how-this-experience-applies-to-your-business","title":"How This Experience Applies to Your Business","text":"<p>Healthcare taught me to build automation that businesses can actually depend on:</p> <ul> <li>High-stakes reliability: Systems that work when it matters most</li> <li>Growth without breaking: Architecture that scales with your business</li> <li>Compliance-first thinking: Security and privacy built in from the start</li> <li>Zero-downtime operations: Updates without business interruption</li> </ul> <ul> <li> <p> Ready to apply this reliability to your automation?</p> <p>Let's discuss how mission-critical engineering discipline can transform your business processes.</p> <p>Book a Free Call </p> </li> </ul> <p> Back to Experience Overview</p>"},{"location":"portfolio/","title":"Featured Projects","text":"<p>Welcome to my portfolio of data science and AI projects. Each project demonstrates my expertise in delivering impactful solutions to real-world business challenges.</p> <ul> <li> <p>AI Customer Care Bot for Dev X</p> <p>An AI-powered chatbot solution for Dev X that enables customer service transformation, featuring Slack integration and sub-3 second response times. Built with OpenAI, Pinecone, and Azure cloud infrastructure to achieve 100% accuracy on initial datasets.</p> </li> <li> <p>Enterprise Chatbot for Company Y</p> <p>A private ChatGPT-like tool for the Company Y that revolutionizes mobility data analysis by combining structured SQL data with unstructured policy documents. Built with OpenAI and modern cloud architecture for comprehensive public sector policy evaluation.</p> </li> </ul>"},{"location":"portfolio/projects/project-1/","title":"AI Customer Care Bot for Dev X","text":"Portfolio Best Practices <p>This is a simplified example project. When creating your own portfolio:</p> <ul> <li>Include detailed technical challenges and how you solved them</li> <li>Add specific metrics and KPIs that demonstrate impact</li> <li>Show code snippets of interesting implementations</li> <li>Include architecture diagrams and system designs</li> <li>Document your decision-making process</li> <li>Highlight your specific contributions to the project</li> <li>Add visuals of the final product (if possible)</li> </ul> <p>Case Study Summary</p> <p>Client: Dev X Website: devx.com Industry: Software Development  </p> <p>Impact Metrics:</p> <ul> <li>90% reduction in customer service overhead (projected)</li> <li>100% accuracy on initial evaluation datasets</li> <li>&lt; 3 second response time for customer inquiries</li> <li>Successfully transitioned 12 CSRs to account management roles</li> <li>$240,000 annual cost savings in customer support operations</li> </ul> <p>Dev X aims to reduce its customer service overhead by 90% over the next three years through AI, enabling their staff to focus on more rewarding roles and build better relationships with clients.</p>"},{"location":"portfolio/projects/project-1/#challenge","title":"Challenge","text":"<p>Their strategy involved transitioning customer service representatives to more rewarding account manager roles to enhance client relationships. They needed an AI solution that could efficiently handle routine customer inquiries while integrating seamlessly with their existing workflows.</p>"},{"location":"portfolio/projects/project-1/#our-approach","title":"Our Approach","text":"<p>We developed an AI chatbot specifically for Dev X's internal use, designed to assist customer service representatives in quickly accessing information. The solution was seamlessly integrated within Slack, the platform already used by their team, allowing for minimal disruption to existing workflows.</p>"},{"location":"portfolio/projects/project-1/#results-impact","title":"Results &amp; Impact","text":"<ul> <li>Response time under 3 seconds</li> <li>100% accuracy on initial evaluation datasets</li> <li>Successful integration with existing Slack workflows</li> <li>Currently expanding knowledge base coverage</li> <li>Simple activation through Slack mentions</li> </ul>"},{"location":"portfolio/projects/project-1/#solution-overview","title":"Solution Overview","text":"<p>Baseline OpenAI end-to-end chat reference architecture</p>"},{"location":"portfolio/projects/project-1/#tech-stack","title":"Tech Stack","text":"<ul> <li>OpenAI</li> <li>Pinecone vector database</li> <li>Slack API integration</li> <li>Microsoft Azure cloud infrastructure</li> <li>Python backend services</li> <li>FastAPI for RESTful endpoints</li> <li>Docker containerization</li> <li>GitHub Actions for CI/CD pipeline</li> </ul>"},{"location":"portfolio/projects/project-1/#additional-context","title":"Additional Context","text":"<ul> <li>Timeline: 3 months</li> <li>Team Size: 2 people (AI Engineer and Data Engineer)</li> <li>Role: AI Engineer</li> <li>Close collaboration with customer service team</li> <li>Ongoing knowledge base expansion</li> <li>Future plans include implementing feedback mechanism</li> </ul> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"},{"location":"portfolio/projects/project-2/","title":"Enterprise Chatbot for the Company Y","text":"Portfolio Best Practices <p>This is a simplified example project. When creating your own portfolio:</p> <ul> <li>Include detailed technical challenges and how you solved them</li> <li>Add specific metrics and KPIs that demonstrate impact</li> <li>Show code snippets of interesting implementations</li> <li>Include architecture diagrams and system designs</li> <li>Document your decision-making process</li> <li>Highlight your specific contributions to the project</li> <li>Add visuals of the final product (if possible)</li> </ul> <p>Case Study Summary</p> <p>Client: Dev X Website: devx.com Industry: Software Development  </p> <p>Impact Metrics:</p> <ul> <li>90% reduction in customer service overhead (projected)</li> <li>100% accuracy on initial evaluation datasets</li> <li>&lt; 3 second response time for customer inquiries</li> <li>Successfully transitioned 12 CSRs to account management roles</li> <li>$240,000 annual cost savings in customer support operations</li> </ul> <p>Company Y an AI project featuring a private ChatGPT-like tool, streamlining mobility data analysis and advancing digital innovation in public sector policy evaluation.</p>"},{"location":"portfolio/projects/project-2/#challenge","title":"Challenge","text":"<p>The regional data team at Company Y faced the challenge of analyzing complex mobility data, including cars, bridges, traffic, and cyclists. Tasked with assessing policy compliance and the impact of changes, they struggled with data scattered across multiple systems, such as the Dexter portal's structured SQL data and various policy documents. This dispersion made analysis laborious, prompting the Province to explore how digitization and AI could streamline the process and foster innovation.</p>"},{"location":"portfolio/projects/project-2/#our-approach","title":"Our Approach","text":"<p>To tackle this challenge, we developed a custom-built AI solution similar to a \"private version of ChatGPT.\" This tool was designed to access and analyze large volumes of PDF documents and structured data exported from the Dexter database. By enabling a ChatGPT-like interaction, users could query this diverse data pool in a conversational manner, leveraging the AI to gain company-specific insights.</p>"},{"location":"portfolio/projects/project-2/#results-impact","title":"Results &amp; Impact","text":"<ul> <li>Successfully integrated structured SQL data and unstructured PDF documents</li> <li>Featured in major company meetings</li> <li>Enabled conversational querying of complex mobility data</li> <li>Streamlined policy compliance assessment</li> <li>Enhanced decision-making through comprehensive data analysis</li> </ul>"},{"location":"portfolio/projects/project-2/#solution-overview","title":"Solution Overview","text":"<p>Baseline OpenAI end-to-end chat reference architecture</p>"},{"location":"portfolio/projects/project-2/#tech-stack","title":"Tech Stack","text":"<ul> <li>OpenAI</li> <li>Pinecone vector database</li> <li>Microsoft Azure cloud infrastructure</li> <li>Python backend services</li> <li>FastAPI for RESTful endpoints</li> <li>Docker containerization</li> <li>GitHub Actions for CI/CD pipeline</li> </ul>"},{"location":"portfolio/projects/project-2/#additional-context","title":"Additional Context","text":"<ul> <li>Timeline: 3 months</li> <li>Team Size: 2 people</li> <li>Role: AI Engineer</li> <li>Expertise in custom chatbot development</li> <li>Specialization in retrieval-augmented generation</li> <li>Focus on OpenAI model integration</li> </ul> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"},{"location":"blog/archive/2026/","title":"2026","text":""},{"location":"blog/category/ai-augmented-development/","title":"AI-Augmented Development","text":""},{"location":"blog/category/developer-productivity/","title":"Developer Productivity","text":""},{"location":"blog/category/ai-augmentation/","title":"AI Augmentation","text":""},{"location":"blog/category/compliance/","title":"Compliance","text":""},{"location":"blog/category/customer-service/","title":"Customer Service","text":""},{"location":"blog/category/ai/","title":"AI","text":""},{"location":"blog/category/innovation/","title":"Innovation","text":""}]}